{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb0a83-dcba-4101-9d51-4293c30b5982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylel\\anaconda3\\Lib\\site-packages\\lightkurve\\config\\__init__.py:119: UserWarning: The default Lightkurve cache directory, used by download(), etc., has been moved to C:\\Users\\kylel\\.lightkurve\\cache. Please move all the files in the legacy directory C:\\Users\\kylel\\.lightkurve-cache to the new location and remove the legacy directory. Refer to https://docs.lightkurve.org/reference/config.html#default-cache-directory-migration for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking exotethys database...\n",
      "Checking ephemerides database...\n",
      "Checking photometry database...\n",
      "Checking catalogues database...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"b4e817fc-68d1-409f-bee3-edd7ab0ac980\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"b4e817fc-68d1-409f-bee3-edd7ab0ac980\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.0.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"b4e817fc-68d1-409f-bee3-edd7ab0ac980\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"b4e817fc-68d1-409f-bee3-edd7ab0ac980\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.6.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"b4e817fc-68d1-409f-bee3-edd7ab0ac980\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated dilution factor for TIC 4918918 = 0.0047\n",
      "Processing light curve for sector 21...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightkurve as lk\n",
    "from transitleastsquares import transitleastsquares\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook, push_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Span, Label, HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "from astroquery.mast import Catalogs\n",
    "\n",
    "# Import the EXOTIC light curve fitter (ensure EXOTIC is installed)\n",
    "from exotic.api.elca import lc_fitter\n",
    "\n",
    "%matplotlib ipympl\n",
    "output_notebook()\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Global data arrays\n",
    "all_time = []\n",
    "all_flux = []\n",
    "\n",
    "# --- User-set default dilution factor (used if catalog query fails)\n",
    "default_dilution_factor = 0.11\n",
    "\n",
    "# --- New Global Settings ---\n",
    "DOWNSAMPLE_THRESHOLD = 5000  # if number of points > threshold then downsample\n",
    "BIN_FACTOR = 5                # factor by which to average data points\n",
    "COARSE_PERIOD_STEPS = 50      # number of steps for coarse TLS search\n",
    "REFINE_PERIOD_STEPS = 200     # number of steps for the refined search\n",
    "VERBOSE = True                # flag for printing progress messages\n",
    "\n",
    "# --- Stellar Parameters ---\n",
    "STAR_MASS_SUN = 0.405      # in solar masses (update as needed)\n",
    "STAR_RADIUS_SUN = 0.406    # in solar radii (update as needed)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def gaussian_filter(data, sigma=3.0):\n",
    "    return gaussian_filter1d(data, sigma=sigma)\n",
    "\n",
    "def clean_data(time, flux):\n",
    "    mask = np.isfinite(time) & np.isfinite(flux)\n",
    "    time_clean = time[mask]\n",
    "    flux_clean = flux[mask]\n",
    "    flux_normalized = flux_clean / np.nanmedian(flux_clean)\n",
    "    return time_clean, flux_normalized\n",
    "\n",
    "def downsample_data(time, flux, factor):\n",
    "    n_points = len(time)\n",
    "    n_bins = n_points // factor\n",
    "    binned_time = np.mean(time[:n_bins*factor].reshape(-1, factor), axis=1)\n",
    "    binned_flux = np.mean(flux[:n_bins*factor].reshape(-1, factor), axis=1)\n",
    "    return binned_time, binned_flux\n",
    "\n",
    "def process_sector(sector, tic_id):\n",
    "    try:\n",
    "        print(f\"Processing light curve for sector {sector}...\")\n",
    "        search_result = lk.search_lightcurve(f'TIC {tic_id}', mission='TESS', sector=sector)\n",
    "        if len(search_result) > 0:\n",
    "            lc_file = search_result.download()\n",
    "            flux = lc_file.flux.value\n",
    "            time = lc_file.time.value\n",
    "            mask = ~np.isnan(flux)\n",
    "            time = time[mask]\n",
    "            flux = flux[mask] / np.nanmedian(flux[mask]) if np.nanmedian(flux[mask]) != 0 else flux[mask]\n",
    "            return time, flux\n",
    "        else:\n",
    "            print(f\"No light curve data found for sector {sector}\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing light curve for sector {sector}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def get_dilution_factor(tic_id, search_radius=21):\n",
    "    try:\n",
    "        target_table = Catalogs.query_criteria(catalog=\"TIC\", ID=tic_id)\n",
    "        if len(target_table) == 0:\n",
    "            print(\"Target not found in TIC; using default dilution factor.\")\n",
    "            return default_dilution_factor\n",
    "        target = target_table[0]\n",
    "        ra, dec = target[\"ra\"], target[\"dec\"]\n",
    "        radius_deg = search_radius / 3600.0\n",
    "        neighbors = Catalogs.query_region(f\"{ra} {dec}\", radius=radius_deg, catalog=\"TIC\")\n",
    "        neighbors = neighbors[neighbors[\"ID\"] != tic_id]\n",
    "        if len(neighbors) == 0:\n",
    "            return 0.0\n",
    "        target_flux = 10**(-0.4 * target[\"Tmag\"])\n",
    "        neighbor_flux = np.sum(10**(-0.4 * neighbors[\"Tmag\"]))\n",
    "        dilution_factor = neighbor_flux / (target_flux + neighbor_flux)\n",
    "        print(f\"Calculated dilution factor for TIC {tic_id} = {dilution_factor:.4f}\")\n",
    "        return dilution_factor\n",
    "    except Exception as e:\n",
    "        print(\"Error computing dilution factor:\", e)\n",
    "        return default_dilution_factor\n",
    "\n",
    "def calculate_t0_uncertainty(time, tls_results, period):\n",
    "    return np.std(tls_results.power) / period * 0.1\n",
    "\n",
    "def calculate_inclination_and_impact(tls_results, semi_major_axis, star_radius):\n",
    "    return 90.0, 0.0, 0.5, 0.05\n",
    "\n",
    "def calculate_semi_major_axis(period, star_mass, period_uncertainty, G=6.67430e-11, solar_mass=1.989e30):\n",
    "    star_mass_kg = star_mass * solar_mass\n",
    "    period_seconds = period * 86400.\n",
    "    semi_major_axis_m = ((G * star_mass_kg * period_seconds**2) / (4 * np.pi**2))**(1/3)\n",
    "    a_AU = semi_major_axis_m / 1.496e11\n",
    "    a_uncertainty = (2/3) * (period_uncertainty / period) * a_AU\n",
    "    return a_AU, a_uncertainty\n",
    "\n",
    "def classify_planet_type(radius_km):\n",
    "    radius_solar = radius_km / 695700.0\n",
    "    if radius_solar >= 0.12:\n",
    "        return 'Red Dwarf Star'\n",
    "    if radius_km < 0.5 * 6371:\n",
    "        return 'Mercury-like'\n",
    "    elif radius_km < 0.9 * 6371:\n",
    "        return 'Venus-like'\n",
    "    elif radius_km < 1.5 * 6371:\n",
    "        return 'Earth-like'\n",
    "    elif radius_km < 2 * 6371:\n",
    "        return 'Super-Earth'\n",
    "    elif radius_km < 3 * 6371:\n",
    "        return 'Mini-Neptune'\n",
    "    elif radius_km < 4 * 6371:\n",
    "        return 'Neptune-like'\n",
    "    else:\n",
    "        return 'Gas Giant (Jupiter/Saturn-like)'\n",
    "\n",
    "def estimate_planet_mass(planet_radius_km, planet_radius_uncertainty_km, host_star_radius_km=None):\n",
    "    R_earth = 6378.0\n",
    "    solar_radius_km = 695700.0\n",
    "    candidate_radius_solar = planet_radius_km / solar_radius_km\n",
    "    if host_star_radius_km is not None:\n",
    "        if planet_radius_km > 0.5 * host_star_radius_km or candidate_radius_solar >= 0.12:\n",
    "            mass_solar = candidate_radius_solar\n",
    "            mass_earth = mass_solar * 332946.0\n",
    "            mass_jup = mass_solar * 1047.0\n",
    "            frac_unc = planet_radius_uncertainty_km / planet_radius_km\n",
    "            return mass_earth, mass_earth * frac_unc, mass_jup, mass_jup * frac_unc\n",
    "    planet_radius_earth = planet_radius_km / R_earth\n",
    "    sigma_R_earth = planet_radius_uncertainty_km / R_earth\n",
    "    if planet_radius_earth < 1.5:\n",
    "        mass_earth = planet_radius_earth**3.7\n",
    "        mass_earth_uncertainty = 3.7 * planet_radius_earth**2.7 * sigma_R_earth\n",
    "    elif planet_radius_earth < 2.5:\n",
    "        mass_earth = 2.7 * (planet_radius_earth**1.3)\n",
    "        mass_earth_uncertainty = 2.7 * 1.3 * planet_radius_earth**0.3 * sigma_R_earth\n",
    "    elif planet_radius_earth < 4.5:\n",
    "        mass_earth = 1.13 * (planet_radius_earth**2.0)\n",
    "        mass_earth_uncertainty = 1.13 * 2.0 * planet_radius_earth**1.0 * sigma_R_earth\n",
    "    elif planet_radius_earth < 6.0:\n",
    "        mass_earth = 1.5 * (planet_radius_earth**2.0)\n",
    "        mass_earth_uncertainty = 1.5 * 2.0 * planet_radius_earth**1.0 * sigma_R_earth\n",
    "    elif planet_radius_earth < 10.0:\n",
    "        mass_earth = planet_radius_earth**2.06\n",
    "        mass_earth_uncertainty = 2.06 * planet_radius_earth**1.06 * sigma_R_earth\n",
    "    elif planet_radius_earth < 20.0:\n",
    "        mass_earth = planet_radius_earth**2.38\n",
    "        mass_earth_uncertainty = 2.38 * planet_radius_earth**1.38 * sigma_R_earth\n",
    "    else:\n",
    "        mass_jup = 10.0\n",
    "        mass_jup_uncertainty = 2.0\n",
    "        mass_earth = mass_jup * 317.8\n",
    "        mass_earth_uncertainty = mass_jup_uncertainty * 317.8\n",
    "        return mass_earth, mass_earth_uncertainty, mass_jup, mass_jup_uncertainty\n",
    "    mass_jup = mass_earth / 317.8\n",
    "    mass_jup_uncertainty = mass_earth_uncertainty / 317.8\n",
    "    return mass_earth, mass_earth_uncertainty, mass_jup, mass_jup_uncertainty\n",
    "\n",
    "def advanced_true_anomaly(t, t0, period, eccentricity, omega):\n",
    "    t = np.atleast_1d(t)\n",
    "    M = 2*np.pi*(t - t0)/period\n",
    "    E = M.copy()\n",
    "    for _ in range(50):\n",
    "        delta = (E - eccentricity*np.sin(E) - M) / (1 - eccentricity*np.cos(E))\n",
    "        E = E - delta\n",
    "        if np.all(np.abs(delta) < 1e-10):\n",
    "            break\n",
    "    f = 2*np.arctan2(np.sqrt(1+eccentricity)*np.sin(E/2), np.sqrt(1-eccentricity)*np.cos(E/2))\n",
    "    f_deg = np.degrees(f + np.radians(omega))\n",
    "    if f_deg.size == 1:\n",
    "        return f_deg[0]\n",
    "    return f_deg\n",
    "\n",
    "def calculate_planet_radius(radius_ratio, star_radius_km, is_binary=False, star_radius2_km=None, flux_ratio=None):\n",
    "    if flux_ratio is not None and flux_ratio > 0:\n",
    "        corrected_radius_ratio = radius_ratio / np.sqrt(1-flux_ratio)\n",
    "    else:\n",
    "        corrected_radius_ratio = radius_ratio\n",
    "    if is_binary and star_radius2_km is not None:\n",
    "        combined_star_radius_km = np.sqrt(star_radius_km**2 + star_radius2_km**2)\n",
    "    else:\n",
    "        combined_star_radius_km = star_radius_km\n",
    "    planet_radius_km = corrected_radius_ratio * combined_star_radius_km\n",
    "    planet_radius_jup = planet_radius_km / 71492\n",
    "    planet_type = classify_planet_type(planet_radius_km)\n",
    "    return planet_radius_km, planet_radius_jup, planet_type\n",
    "\n",
    "def calculate_transit_parameters(tls_results, flux, star_radius, star_mass, period_uncertainty, is_binary=True, star_radius2=None, dilution_factor=0.0):\n",
    "    flux_median = np.nanmedian(flux)\n",
    "    flux_min = np.min(flux)\n",
    "    measured_depth = (flux_median - flux_min)/flux_median\n",
    "    if dilution_factor > 0:\n",
    "        transit_depth = measured_depth/(1-dilution_factor)\n",
    "    else:\n",
    "        transit_depth = measured_depth\n",
    "    transit_depth_uncertainty = np.std(flux-flux_median)/flux_median\n",
    "    if transit_depth <= 0:\n",
    "        raise ValueError(\"Transit depth is non-positive.\")\n",
    "    radius_ratio = np.sqrt(transit_depth)\n",
    "    radius_ratio_uncertainty = (transit_depth_uncertainty/(2*np.sqrt(transit_depth))) if transit_depth > 0 else np.nan\n",
    "    period = tls_results.period\n",
    "    t0 = tls_results.T0\n",
    "    duration = tls_results.duration\n",
    "    depth_ppt = transit_depth*1e3\n",
    "    depth_ppm = transit_depth*1e6\n",
    "    depth_uncertainty_ppt = transit_depth_uncertainty*1e3\n",
    "    depth_uncertainty_ppm = transit_depth_uncertainty*1e6\n",
    "    semi_major_axis, semi_major_axis_uncertainty = calculate_semi_major_axis(period, star_mass, period_uncertainty)\n",
    "    inclination, impact_parameter, inclination_unc, impact_parameter_unc = calculate_inclination_and_impact(tls_results, semi_major_axis, star_radius)\n",
    "    planet_radius_km, planet_radius_jup, planet_type = calculate_planet_radius(radius_ratio, star_radius*696340, is_binary=is_binary, star_radius2_km=star_radius2, flux_ratio=dilution_factor)\n",
    "    planet_radius_uncertainty_km = radius_ratio_uncertainty*(star_radius*696340)\n",
    "    mass_earth, mass_earth_unc, mass_jup, mass_jup_unc = estimate_planet_mass(planet_radius_km, planet_radius_uncertainty_km, host_star_radius_km=star_radius*696340)\n",
    "    return {\n",
    "        \"transit_depth\": transit_depth,\n",
    "        \"transit_depth_uncertainty\": transit_depth_uncertainty,\n",
    "        \"depth_ppt\": depth_ppt,\n",
    "        \"depth_ppm\": depth_ppm,\n",
    "        \"depth_uncertainty_ppt\": depth_uncertainty_ppt,\n",
    "        \"depth_uncertainty_ppm\": depth_uncertainty_ppm,\n",
    "        \"radius_ratio\": radius_ratio,\n",
    "        \"radius_ratio_uncertainty\": radius_ratio_uncertainty,\n",
    "        \"period\": period,\n",
    "        \"t0\": t0,\n",
    "        \"duration\": duration,\n",
    "        \"semi_major_axis\": semi_major_axis,\n",
    "        \"semi_major_axis_uncertainty\": semi_major_axis_uncertainty,\n",
    "        \"inclination\": inclination,\n",
    "        \"inclination_uncertainty\": inclination_unc,\n",
    "        \"impact_parameter\": impact_parameter,\n",
    "        \"impact_parameter_uncertainty\": impact_parameter_unc,\n",
    "        \"planet_radius_km\": planet_radius_km,\n",
    "        \"planet_radius_jup\": planet_radius_jup,\n",
    "        \"planet_type\": planet_type,\n",
    "        \"planet_mass_earth\": mass_earth,\n",
    "        \"planet_mass_earth_uncertainty\": mass_earth_unc,\n",
    "        \"planet_mass_jup\": mass_jup,\n",
    "        \"planet_mass_jup_uncertainty\": mass_jup_unc\n",
    "    }\n",
    "\n",
    "def plot_in_out_transits(time, flux, period, t0, duration):\n",
    "    phases = ((time - t0 + 0.5*period) % period)-0.5*period\n",
    "    in_transit = np.abs(phases) < (duration/2)\n",
    "    out_transit = ~in_transit\n",
    "    fig_in_out = figure(title='In-Transit vs Out-of-Transit Data',\n",
    "                        x_axis_label='Time (days)', y_axis_label='Relative Flux',\n",
    "                        width=800, height=400)\n",
    "    fig_in_out.circle(time[out_transit], flux[out_transit], size=3, color='blue', legend_label='Out-of-Transit')\n",
    "    fig_in_out.circle(time[in_transit], flux[in_transit], size=3, color='red', legend_label='In-Transit')\n",
    "    fig_in_out.add_tools(HoverTool(tooltips=[(\"Time\", \"@x\"), (\"Flux\", \"@y\")]))\n",
    "    return fig_in_out\n",
    "\n",
    "def display_tpf(tic_id, sector):\n",
    "    try:\n",
    "        tpf_search = lk.search_targetpixelfile(f'TIC {tic_id}', mission='TESS', sector=sector)\n",
    "        if len(tpf_search) > 0:\n",
    "            tpf = tpf_search.download()\n",
    "            tpf.plot(aperture_mask=True)\n",
    "            plt.title(f'TPF for TIC {tic_id} Sector {sector}')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"No TPF found for TIC {tic_id} in sector {sector}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying TPF for sector {sector}: {e}\")\n",
    "\n",
    "def plot_phase_folded_lightcurve(tls_results, time, flux, bins=500):\n",
    "    period = tls_results.period\n",
    "    t0 = tls_results.T0\n",
    "    model_time = tls_results.model_lightcurve_time\n",
    "    model_flux = tls_results.model_lightcurve_model\n",
    "    phase = ((time - t0 + 0.5*period) % period)-0.5*period\n",
    "    sort_idx = np.argsort(phase)\n",
    "    phase_sorted = phase[sort_idx]\n",
    "    flux_sorted = flux[sort_idx]\n",
    "    model_phase = ((model_time - t0 + 0.5*period) % period)-0.5*period\n",
    "    model_sort_idx = np.argsort(model_phase)\n",
    "    model_phase_sorted = model_phase[model_sort_idx]\n",
    "    model_flux_sorted = model_flux[model_sort_idx]\n",
    "    phase_bins = np.linspace(-0.5*period, 0.5*period, bins+1)\n",
    "    binned_phase, binned_flux = [], []\n",
    "    for i in range(len(phase_bins)-1):\n",
    "        in_bin = (phase_sorted>=phase_bins[i]) & (phase_sorted<phase_bins[i+1])\n",
    "        if np.any(in_bin):\n",
    "            binned_phase.append(np.mean(phase_sorted[in_bin]))\n",
    "            binned_flux.append(np.mean(flux_sorted[in_bin]))\n",
    "    binned_phase = np.array(binned_phase)\n",
    "    binned_flux = np.array(binned_flux)\n",
    "    model_flux_interp = np.interp(phase_sorted, model_phase_sorted, model_flux_sorted)\n",
    "    residuals = flux_sorted - model_flux_interp\n",
    "    fig, (ax_top, ax_bottom) = plt.subplots(2,1,sharex=True, gridspec_kw={'height_ratios':[3,1]}, figsize=(8,6))\n",
    "    ax_top.scatter(phase_sorted, flux_sorted, s=3, color='gray', alpha=0.4, label='Data')\n",
    "    ax_top.scatter(binned_phase, binned_flux, s=3, color='red', edgecolor='black', zorder=5, label='Binned')\n",
    "    ax_top.plot(model_phase_sorted, model_flux_sorted, color='orange', lw=2, label='TLS Model')\n",
    "    ax_top.set_ylabel(\"Relative Flux\")\n",
    "    ax_top.set_title(f\"Phase-folded Light Curve (P = {period:.5f} d)\")\n",
    "    ax_top.legend(loc='best')\n",
    "    ax_top.set_xlim(-0.10, 0.10)\n",
    "    ax_bottom.scatter(phase_sorted, residuals, s=5, color='gray', alpha=0.6)\n",
    "    ax_bottom.axhline(0, color='red', lw=1)\n",
    "    ax_bottom.set_xlabel(\"Phase (days)\")\n",
    "    ax_bottom.set_ylabel(\"Residuals\")\n",
    "    ax_bottom.set_xlim(-0.3, 0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_tls_periodogram(main_tls, main_params, tic_id):\n",
    "    fig = figure(title=f'TLS Periodogram for TIC {tic_id}', x_axis_label='Period (days)', y_axis_label='SNR', width=800, height=400)\n",
    "    fig.line(main_tls.periods, main_tls.power, line_width=1, line_color='green', legend_label='TLS Power')\n",
    "    best_period = main_params[\"period\"]\n",
    "    best_SNR = max(main_tls.power)\n",
    "    span = Span(location=best_period, dimension='height', line_color='green', line_dash='dashed', line_width=1.5)\n",
    "    fig.add_layout(span)\n",
    "    label = Label(x=best_period, y=best_SNR, text=f\"Main: {best_period:.6f} d (SNR={best_SNR:.1f})\", text_color=\"green\", text_font_size=\"8pt\")\n",
    "    fig.add_layout(label)\n",
    "    fig.add_tools(HoverTool(tooltips=[(\"Period\", \"@x\"), (\"SNR\", \"@y\")]))\n",
    "    show(fig, notebook_handle=True)\n",
    "    push_notebook()\n",
    "\n",
    "def plot_detrended_lightcurve_with_transits(time, flux, period, t0, duration):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(time, flux, 'k.', markersize=2, label='Detrended Data')\n",
    "    transit_times = []\n",
    "    t_min, t_max = np.min(time), np.max(time)\n",
    "    n_before = int(np.floor((t_min-t0)/period))\n",
    "    n_after = int(np.ceil((t_max-t0)/period))\n",
    "    for n in range(n_before, n_after+1):\n",
    "        transit_time = t0 + n*period\n",
    "        if t_min <= transit_time <= t_max:\n",
    "            transit_times.append(transit_time)\n",
    "            plt.axvline(x=transit_time, color='green', linestyle='dashed', lw=1)\n",
    "    plt.xlabel(\"Time (days)\")\n",
    "    plt.ylabel(\"Normalized Flux\")\n",
    "    plt.title(\"Detrended Light Curve with Transit Markers\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_tls_search(time, flux, period_min, period_max):\n",
    "    original_length = len(time)\n",
    "    if original_length > DOWNSAMPLE_THRESHOLD:\n",
    "        print(f\"Data length ({original_length}) exceeds threshold. Downsampling by factor {BIN_FACTOR}.\")\n",
    "        time, flux = downsample_data(time, flux, BIN_FACTOR)\n",
    "    else:\n",
    "        print(\"No downsampling needed.\")\n",
    "    print(\"Running coarse TLS search...\")\n",
    "    model = transitleastsquares(time, flux)\n",
    "    coarse_result = model.power(period_min=period_min, period_max=period_max, period_steps=COARSE_PERIOD_STEPS, show_progress_bar=VERBOSE)\n",
    "    if coarse_result.periods.size == 0:\n",
    "        raise ValueError(\"No significant periods found in coarse search.\")\n",
    "    best_period_coarse = coarse_result.period\n",
    "    refine_window = 0.1 * best_period_coarse\n",
    "    new_period_min = max(period_min, best_period_coarse - refine_window)\n",
    "    new_period_max = min(period_max, best_period_coarse + refine_window)\n",
    "    print(f\"Refining TLS search around best period {best_period_coarse:.5f} d between {new_period_min:.5f} and {new_period_max:.5f} d\")\n",
    "    refined_result = model.power(period_min=new_period_min, period_max=new_period_max, period_steps=REFINE_PERIOD_STEPS, show_progress_bar=VERBOSE)\n",
    "    return refined_result\n",
    "\n",
    "def compute_a_over_rstar_from_kepler(period_days, star_mass_sun, star_radius_sun):\n",
    "    MSUN_KG = 1.98847e30\n",
    "    RSUN_M = 6.95700e8\n",
    "    G = 6.67430e-11\n",
    "    period_s = period_days * 86400.0\n",
    "    a_m = (G * (star_mass_sun * MSUN_KG) * period_s**2 / (4 * np.pi**2))**(1/3)\n",
    "    a_over_r = a_m / (star_radius_sun * RSUN_M)\n",
    "    return a_over_r\n",
    "\n",
    "def main():\n",
    "    tic_id = \"4918918\"  # example TIC ID; update as needed\n",
    "    sectors = [21, 48]        # example sector; update as needed\n",
    "    global all_time, all_flux\n",
    "    dilution_factor = get_dilution_factor(tic_id, search_radius=21)\n",
    "    for sector in sectors:\n",
    "        time, flux = process_sector(sector, tic_id)\n",
    "        if time is not None and flux is not None:\n",
    "            all_time.append(time)\n",
    "            all_flux.append(flux)\n",
    "        display_tpf(tic_id, sector)\n",
    "    if not all_time or not all_flux:\n",
    "        print(\"No valid light curve data available after processing.\")\n",
    "        return\n",
    "    all_time_np = np.concatenate(all_time)\n",
    "    all_flux_np = np.concatenate(all_flux)\n",
    "    all_time_np, all_flux_np = clean_data(all_time_np, all_flux_np)\n",
    "    lc = lk.LightCurve(time=all_time_np, flux=all_flux_np)\n",
    "    flat_lc = lc.flatten(window_length=401)\n",
    "    all_time_np = flat_lc.time.value\n",
    "    all_flux_np = flat_lc.flux.value\n",
    "    ld_coeffs = [0, 0]\n",
    "    try:\n",
    "        PERIOD_MIN = 19  # days\n",
    "        PERIOD_MAX = 20   # days\n",
    "        tls_results = run_tls_search(all_time_np, all_flux_np, PERIOD_MIN, PERIOD_MAX)\n",
    "        if tls_results.periods.size > 0:\n",
    "            period = tls_results.period\n",
    "            period_uncertainty = tls_results.period_uncertainty\n",
    "            t0 = tls_results.T0\n",
    "            duration = tls_results.duration\n",
    "            transit_params = calculate_transit_parameters(\n",
    "                tls_results, all_flux_np, star_radius=0.406, star_mass=0.405,\n",
    "                period_uncertainty=period_uncertainty,\n",
    "                dilution_factor=dilution_factor, is_binary=True, star_radius2=0.0\n",
    "            )\n",
    "            # Force transit midtime into full BJD (i.e., add 2457000)\n",
    "            tmid_full = t0 + 2457000.0\n",
    "            print(\"Orbital Parameters:\")\n",
    "            print(f\"  Period: {transit_params['period']:.6f} ± {period_uncertainty:.6f} days\")\n",
    "            print(f\"  Transit Midpoint (t0): {tmid_full:.6f} days ± {calculate_t0_uncertainty(all_time_np, tls_results, period):.6f}\")\n",
    "            print(f\"  Duration: {transit_params['duration']*24:.2f} hours\")\n",
    "            print(f\"  Semi-major Axis (a): {transit_params['semi_major_axis']:.4f} ± {transit_params['semi_major_axis_uncertainty']:.4f} AU\")\n",
    "            print(f\"  Transit Depth: {transit_params['depth_ppt']:.2f} ± {transit_params['depth_uncertainty_ppt']:.2f} ppt, {transit_params['depth_ppm']:.2f} ± {transit_params['depth_uncertainty_ppm']:.2f} ppm\")\n",
    "            print(f\"  Radius Ratio (Rp/Rs): {transit_params['radius_ratio']:.4f} ± {transit_params['radius_ratio_uncertainty']:.4f}\")\n",
    "            print(f\"  Candidate Radius: {transit_params['planet_radius_km']:.2f} km, {transit_params['planet_radius_jup']:.4f} R_Jup\")\n",
    "            print(f\"  Candidate Type: {transit_params['planet_type']}\")\n",
    "            print(f\"  Synthetic Companion Mass: {transit_params['planet_mass_earth']:.2f} ± {transit_params['planet_mass_earth_uncertainty']:.2f} M_Earth, {transit_params['planet_mass_jup']:.4f} ± {transit_params['planet_mass_jup_uncertainty']:.4f} M_Jup\")\n",
    "            plot_phase_folded_lightcurve(tls_results, all_time_np, all_flux_np, bins=100)\n",
    "            plot_tls_periodogram(tls_results, transit_params, tic_id)\n",
    "            plot_detrended_lightcurve_with_transits(all_time_np, all_flux_np, period, t0, duration)\n",
    "            \n",
    "            print(\"\\nStarting fully automated EXOTIC phase-folded transit fitting...\")\n",
    "            # Always use a fixed offset of 2457000.0 so that tmid is in full BJD\n",
    "            t_offset = 2457000.0\n",
    "            \n",
    "            # Compute a/R* from Kepler's Third Law:\n",
    "            auto_ars = compute_a_over_rstar_from_kepler(period, STAR_MASS_SUN, STAR_RADIUS_SUN)\n",
    "            print(f\"Auto-computed a/R* = {auto_ars:.2f}\")\n",
    "            \n",
    "            # Instead of relying on TLS t0, let EXOTIC fit for mid-transit.\n",
    "            # Set an initial tmid using TLS but with wide bounds, converted to full BJD.\n",
    "            tmid_init = t0 + t_offset\n",
    "            \n",
    "            # Phase-fold the light curve (for fitting) using TLS period and t0.\n",
    "            folded_phase = ((all_time_np - t0 + 0.5*period) % period) / period - 0.5\n",
    "            folded_time = folded_phase * period + t0\n",
    "            pdur = 2 * np.arctan(1.0/auto_ars) / (2*np.pi)\n",
    "            transit_mask = np.abs(folded_phase) < 2*pdur\n",
    "            if np.sum(transit_mask) == 0:\n",
    "                raise Exception(\"No phase-folded data within the transit window found.\")\n",
    "            fit_time = folded_time[transit_mask]\n",
    "            fit_flux = all_flux_np[transit_mask]\n",
    "            flux_err = np.full_like(fit_flux, np.std(fit_flux))\n",
    "            airmass = np.zeros_like(fit_time)\n",
    "            fit_time = np.array(fit_time, dtype=float)\n",
    "            fit_flux = np.array(fit_flux, dtype=float)\n",
    "            flux_err = np.array(flux_err, dtype=float)\n",
    "            airmass = np.array(airmass, dtype=float)\n",
    "            \n",
    "            # Build transit parameter dictionary for EXOTIC.\n",
    "            rprs_est = np.sqrt(transit_params[\"transit_depth\"])\n",
    "            tpars = {\n",
    "                \"rprs\": rprs_est,\n",
    "                \"ars\": auto_ars,\n",
    "                \"per\": period,\n",
    "                \"inc\": 90.0,         # initial guess; allow EXOTIC to adjust inclination\n",
    "                \"tmid\": tmid_init,   # initial guess (full BJD)\n",
    "                \"omega\": 0.0,\n",
    "                \"ecc\": 0.0,\n",
    "                \"a1\": 0.0,\n",
    "                \"a2\": 0.0,\n",
    "                \"u0\": 0.0,\n",
    "                \"u1\": 0.0,\n",
    "                \"u2\": 0.0,\n",
    "                \"u3\": 0.0\n",
    "            }\n",
    "            # Set wide bounds for tmid so that EXOTIC can fit it independently.\n",
    "            mybounds = {\n",
    "                \"rprs\": [0, 3*rprs_est],\n",
    "                \"tmid\": [tmid_init - 0.5, tmid_init + 0.5],\n",
    "                \"inc\": [80, 90],\n",
    "                \"ars\": [auto_ars*0.8, auto_ars*1.2]\n",
    "            }\n",
    "            try:\n",
    "                phase_fit = lc_fitter(fit_time + t_offset, fit_flux, flux_err, airmass, tpars, mybounds)\n",
    "            except Exception as e:\n",
    "                print(\"EXOTIC phase-folded fitting failed:\", e)\n",
    "                phase_fit = None\n",
    "            if phase_fit is not None:\n",
    "                print(\"\\nEXOTIC Phase-Folded Fit Results:\")\n",
    "                for key in phase_fit.bounds.keys():\n",
    "                    print(f\"{key}: {phase_fit.parameters[key]:.6f} ± {phase_fit.errors[key]}\")\n",
    "                fig_best = phase_fit.plot_bestfit(title=\"EXOTIC Phase-Folded Fit\", bin_dt=0.5/24.)\n",
    "                plt.show()\n",
    "                fig_triangle = phase_fit.plot_triangle()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"EXOTIC phase-folded fitting did not produce valid results.\")\n",
    "        else:\n",
    "            print(\"No significant periods found in TLS analysis.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during TLS analysis: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
